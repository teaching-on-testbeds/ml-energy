{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network Classifier"
   ],
   "id": "1938d588-abd0-4b63-bf0a-208d4bfc7f24"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ],
   "id": "ef95cfc2-1159-4060-a0e0-54f44e4b785c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Here, we’ll load the processed data defined in the previous notebook"
   ],
   "id": "a1cdcddd-d9f9-4237-bf3d-8222481b4253"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_scale = np.load('instrument_dataset/uiowa_std_scale_train_data.npy')\n",
    "ytr = np.load('instrument_dataset/uiowa_permuted_train_labels.npy')\n",
    "Xts_scale = np.load('instrument_dataset/uiowa_std_scale_test_data.npy')\n",
    "yts = np.load('instrument_dataset/uiowa_test_labels.npy')"
   ],
   "id": "8f6644d2-b795-46a0-b9bc-9f96728d1367"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the classification model"
   ],
   "id": "53c523c1-e87b-4a63-a153-d0f90a1a51a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "import tensorflow.keras.backend as K"
   ],
   "id": "7ad8b999-c934-47a2-99d6-8bbc10f349ac"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a neural network `model` with:\n",
    "\n",
    "-   `nh=256` hidden units in a single dense hidden layer\n",
    "-   `sigmoid` activation at hidden units\n",
    "-   select the input and output shapes, and output activation, according to the problem requirements."
   ],
   "id": "2fead9e9-0ecc-43af-a742-ae4a6ccf3269"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - construct the model\n",
    "nh = 256\n",
    "model = Sequential()"
   ],
   "id": "5e0f2454-4c72-494d-a0da-58a4c591890e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the model summary."
   ],
   "id": "95a5284a-c982-45c9-9643-dc6a553bbf66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model summary\n",
    "model.summary()"
   ],
   "id": "30f4003d-b626-4704-a3ed-7e34ce1634d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also visualize the model with\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ],
   "id": "9cfc9447-3bd5-43b9-a63a-ca683657c974"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an optimizer and compile the model. Select the appropriate loss function for this multi-class classification problem, and use an accuracy metric. For the optimizer, use the Adam optimizer with a learning rate of 0.001"
   ],
   "id": "38a1bd59-21e9-4b46-a4cf-bc810289aadc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - create optimizer and compile the model\n",
    "opt = \n",
    "loss_fn = \n",
    "\n",
    "model.compile()"
   ],
   "id": "af218d39-ff30-4987-bd72-1ca454e81026"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model for 10 epochs using the scaled data for both training and validation, and save the training history in \\`hist\\`.\n",
    "\n",
    "Use the `validation_data` option to pass the *test* data. (This is OK because we are not going to use this data as part of the training process, such as for early stopping - we’re just going to compute the accuracy on the data so that we can see how training and test loss changes as the model is trained.)\n",
    "\n",
    "Use a batch size of 128. Your final accuracy should be greater than 99%."
   ],
   "id": "3d1eedec-c54f-4788-8076-6f81ce0b450f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - fit model and save training history\n",
    "n_epochs = 10\n",
    "\n",
    "hist = model.fit()"
   ],
   "id": "1aa73069-0088-4897-9e67-a904efac204d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and validation accuracy saved in `hist.history` dictionary, on the same plot. This gives one accuracy value per epoch. You should see that the validation accuracy saturates around 99%. After that it may “bounce around” a little due to the noise in the stochastic mini-batch gradient descent.\n",
    "\n",
    "Make sure to label each axis, and each series (training vs. validation/test)."
   ],
   "id": "f73ba34c-d019-4c01-abbf-c37f38b98721"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - plot the training and validation accuracy in one plot"
   ],
   "id": "040a414c-2ba2-4706-992d-90cc4606b8d0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and validation loss values saved in the `hist.history` dictionary, on the same plot. You should see that the training loss is steadily decreasing. Use the [`semilogy` plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.semilogy.html) so that the y-axis is log scale.\n",
    "\n",
    "Make sure to label each axis, and each series (training vs. validation/test)."
   ],
   "id": "6a5cd9f7-e0ba-4af8-a080-d7ef6ae3d94b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - plot the training and validation loss in one plot"
   ],
   "id": "8103c003-4273-4f59-b53d-8858013bcba3"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
