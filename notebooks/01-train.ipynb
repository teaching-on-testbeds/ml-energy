{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Neural Network Classifier"
   ],
   "id": "3245f5da-1234-4864-b945-1bd3a55e155e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ],
   "id": "32886d4c-5da9-411a-8ae1-ed7bf1e7e9d7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Here, we’ll load the processed data defined in the previous notebook"
   ],
   "id": "5638471a-25f5-4912-924e-c3e98674dff2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_scale = np.load('instrument_dataset/uiowa_std_scale_train_data.npy')\n",
    "ytr = np.load('instrument_dataset/uiowa_permuted_train_labels.npy')\n",
    "Xts_scale = np.load('instrument_dataset/uiowa_std_scale_test_data.npy')\n",
    "yts = np.load('instrument_dataset/uiowa_test_labels.npy')"
   ],
   "id": "29be4151-d866-417d-8d91-f8e49dd58ce3"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the classification model"
   ],
   "id": "14293768-b791-4380-9b13-2f79a3c2312f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "import tensorflow.keras.backend as K"
   ],
   "id": "97dfcc73-4919-4f3e-894f-7f391ba6438a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a neural network `model` with:\n",
    "\n",
    "-   `nh=256` hidden units in a single dense hidden layer\n",
    "-   `sigmoid` activation at hidden units\n",
    "-   select the input and output shapes, and output activation, according to the problem requirements."
   ],
   "id": "a7baff84-931c-42ca-9712-f4c8f292a09a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - construct the model\n",
    "nh = 256\n",
    "model = Sequential()"
   ],
   "id": "cd6969f8-8e59-480f-b385-57af250deb7d"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the model summary."
   ],
   "id": "8573f55f-0c5a-48ae-8874-6a4954a102c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the model summary\n",
    "model.summary()"
   ],
   "id": "2b496834-13cc-41af-b0be-ccbc785b2d5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also visualize the model with\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ],
   "id": "96a508c7-55fb-4901-be0b-4d3ec84c3083"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an optimizer and compile the model. Select the appropriate loss function for this multi-class classification problem, and use an accuracy metric. For the optimizer, use the Adam optimizer with a learning rate of 0.001"
   ],
   "id": "f76822a8-531b-4197-8d36-b07e124e8d8e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - create optimizer and compile the model\n"
   ],
   "id": "c6776712-acce-4968-b728-05e369a84af0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model for 10 epochs using the scaled data for both training and validation, and save the training history in \\`hist\\`.\n",
    "\n",
    "Use the `validation_data` option to pass the *test* data. (This is OK because we are not going to use this data as part of the training process, such as for early stopping - we’re just going to compute the accuracy on the data so that we can see how training and test loss changes as the model is trained.)\n",
    "\n",
    "Use a batch size of 128. Your final accuracy should be greater than 99%."
   ],
   "id": "f7b2f65b-8bda-4e09-96c0-2b09daedb479"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - fit model and save training history\n",
    "n_epochs = 10\n",
    "\n",
    "hist = model.fit()"
   ],
   "id": "81041f81-17c1-46d5-baf5-96f46658450b"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and validation accuracy saved in `hist.history` dictionary, on the same plot. This gives one accuracy value per epoch. You should see that the validation accuracy saturates around 99%. After that it may “bounce around” a little due to the noise in the stochastic mini-batch gradient descent.\n",
    "\n",
    "Make sure to label each axis, and each series (training vs. validation/test)."
   ],
   "id": "87830374-038c-4f05-a375-5c0a4f480f47"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - plot the training and validation accuracy in one plot"
   ],
   "id": "e172c3f8-8b46-43ac-a921-3db9d34dbeb0"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training and validation loss values saved in the `hist.history` dictionary, on the same plot. You should see that the training loss is steadily decreasing. Use the [`semilogy` plot](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.semilogy.html) so that the y-axis is log scale.\n",
    "\n",
    "Make sure to label each axis, and each series (training vs. validation/test)."
   ],
   "id": "ca2b442c-1016-4a01-b269-ca035d13d2df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - plot the training and validation loss in one plot"
   ],
   "id": "3d0bec6f-dc06-4f7b-9672-af3889b8f097"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
