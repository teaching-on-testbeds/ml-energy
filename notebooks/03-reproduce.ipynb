{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573bb08e-ec00-417e-b1bd-c2c50ed2e309",
   "metadata": {},
   "source": [
    "## Visualizing Energy Time Tradeoff\n",
    "\n",
    "In this notebook, we’ll attempt to visualize the relation of energy\n",
    "consumption during training and training time with varying batch size\n",
    "and GPU power limit. We reproduce Fig. 16 (d) of the\n",
    "[Zeus](https://www.usenix.org/system/files/nsdi23-you.pdf) paper to\n",
    "study is relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaad01b-bf66-49de-8707-2328c8b93a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9de7bc-7a15-43fd-a476-f5e231cc014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbee2c-796b-425a-8f73-fcb534f26c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeus.monitor import ZeusMonitor\n",
    "from zeus.optimizer import GlobalPowerLimitOptimizer\n",
    "from zeus.optimizer.power_limit import MaxSlowdownConstraint\n",
    "from zeus.util.env import get_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30791514-0b56-4f75-90fe-efd138bac5b8",
   "metadata": {},
   "source": [
    "### Loading the train and test Data\n",
    "\n",
    "We would be using the Imagenet dataset for this experiment. The total\n",
    "datasize of imagenet is approximately 150Gbs. Downloading this set on\n",
    "the server takes a significant amount of time (4 - 6 hours) so it is\n",
    "advised to start with the notebook early."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b127a0f-01c1-45ac-b0c0-99eba0850b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the train dataset (Takes ~ 4 hours)\n",
    "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_train.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a9a7b-0f00-45d5-8410-72fd799e0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the validataion dataset (Takes ~ 6 minutes)\n",
    "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_img_val.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4ddd9-e4bf-4503-a926-c92d24804d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading the imagenet devkit dataset for pytorch to pre-process dataset (Takes ~ 10 seconds)\n",
    "!wget https://image-net.org/data/ILSVRC/2012/ILSVRC2012_devkit_t12.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1f5656-3e96-43a9-acf7-4b99f4b6bd1f",
   "metadata": {},
   "source": [
    "Define data tranformations that will be applied to the training and test\n",
    "dataset. We perform the following tranformations:\n",
    "\n",
    "-   Cropping each image to 224\\*224\n",
    "-   Augmenting the dataset with flipping images horizontly\n",
    "-   Tranforming image array to a tensor for it to be torch compatible\n",
    "-   Normalize the train and test dataet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ff18a-b155-49e1-b54e-b3be72cf2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "\n",
    "transformations = [transforms.RandomResizedCrop(224),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             transforms.ToTensor(),\n",
    "             normalize,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215abe23-7c28-4806-89b1-b47f988a4867",
   "metadata": {},
   "source": [
    "Now load the downloaded train and test dataset as a torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7ed21-ab7d-47f7-bc61-4c6f2b2eb57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageNet('./', split = 'train', tranform = transformations)\n",
    "\n",
    "valid_dataset = torchvision.datasets.ImageNet('./', split = 'test', tranform = transformations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a6b2ea-9370-47ae-bbf0-510b74f5e9b2",
   "metadata": {},
   "source": [
    "### Define the Neural Network\n",
    "\n",
    "We will use the Resnet-50 architecture as our neural network for this\n",
    "experiement. Follow these steps to load the pre-defined Resnet-50\n",
    "architecture from the torchvision.models module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4c25d-db8e-4e57-97c2-7d901c41719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting the device to CUDA if GPU is available for super-fast training\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aed841-1c19-4fdd-9a3b-153c8c74dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCH = 'resnet50' #Defining the architecture to be used\n",
    "model = models.__dict__[ARCH]() #Loading the architecture\n",
    "\n",
    "torch.cuda.set_device(torch.cuda.device(device))\n",
    "model.cuda(device) #Placing the model in the GPU, if available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf87660-eb2f-49fe-af7f-78b8610ed838",
   "metadata": {},
   "source": [
    "### Train the Neural Network\n",
    "\n",
    "To train the network, we have to select an optimizer and a loss\n",
    "function.\n",
    "\n",
    "Since this is a multi-class classification problem, we select the cross\n",
    "entropy loss.\n",
    "\n",
    "We will also choose an optimizer (Adadelta) as defined in Section 6.1 of\n",
    "the [Zeus](https://www.usenix.org/system/files/nsdi23-you.pdf) paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268e2f11-a809-4570-a41c-2b0fa42451ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the criteria to Cross-Entropy loss\n",
    "criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "optimizer = torch.optim.Adadelta(\n",
    "    model.parameters(),\n",
    "    lr = 0.1\n",
    ")\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb974c1f-a824-4d70-b455-c2c2011e1454",
   "metadata": {},
   "source": [
    "To pass data to our model, we will prepare a DataLoader - this will\n",
    "iterate over the data and “batch” it for us according to the batch size\n",
    "we specify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa6d768-655d-464f-be23-4a928e1d7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the torch datasets as dataloaders to pass in the model; Using a default batch size of 128; shuffle for training, not for validation\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "val_loader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83895ca-2cba-4a53-8249-66dde8a9b535",
   "metadata": {},
   "source": [
    "Now we are ready to define our training function:\n",
    "\n",
    "-   Get a batch of training data from the `train_loader`.\n",
    "-   Zero the gradients of the `optimizer`. (This is necessary because by\n",
    "    default, they accumulate.)\n",
    "-   Do a forward pass on the batch of training data.\n",
    "-   Use the predictions from this forward pass to compute the loss.\n",
    "-   Then, do a backwards pass where we compute the gradients.\n",
    "-   Update the weights of the optimizer using these gradients.\n",
    "\n",
    "We stop the training when either a minimum validation accuracy is\n",
    "reached or the max number of epochs have taken place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6a940-9563-40f4-8fa7-99078595acab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(data_loader):\n",
    "\n",
    "    #Put the model in training mode\n",
    "    model.train()\n",
    "\n",
    "    for i, (images, target) in enumerate(data_loader):\n",
    "\n",
    "        # Load data to GPU\n",
    "        images = images.cuda(device, non_blocking=True)\n",
    "        target = target.cuda(device, non_blocking=True)\n",
    "\n",
    "        # compute output\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd7a74-27a7-4dbb-ad01-84f75ba3c9eb",
   "metadata": {},
   "source": [
    "We will also define a function for evaluating the model without\n",
    "training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ad0fc-8f9b-454d-b012-a8e312180134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First define an accuracy function to get the accuracy of a batch prediction\n",
    "def accuracy(predicted,actual):\n",
    "    _, predictions = torch.max(predicted,dim=1)\n",
    "    return torch.tensor(torch.sum(predictions==actual).item()/len(predictions))\n",
    "\n",
    "\n",
    "def eval_model(data_loader):\n",
    "    eval_accuracy = 0\n",
    "    running_samples = 0\n",
    "\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation for faster computation/reduced memory\n",
    "    with torch.no_grad():\n",
    "\n",
    "      for i, (images, target) in enumerate(data_loader):\n",
    "          # Every data instance is an X, y pair\n",
    "          images = images.cuda(device, non_blocking=True)\n",
    "          target = target.cuda(device, non_blocking=True)\n",
    "\n",
    "          # Forward pass makes predictions for this batch\n",
    "          output = model(images)\n",
    "\n",
    "          # Compute the accuracy\n",
    "          accuracy_batch = accuracy(output, target)\n",
    "          eval_accuracy = (eval_accuracy*running_samples + accuracy_batch*images.shape[0])/(running_samples+images.shape[0])\n",
    "          running_samples += images.shape[0]\n",
    "    \n",
    "    return eval_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1692ac3-ba94-4c5a-84cf-a1706a835156",
   "metadata": {},
   "source": [
    "Now, we will loop over epochs, train the model for one epoch, and then\n",
    "evaluate its performance on the validation data at the end of each\n",
    "epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634447a-869c-45aa-87f4-56aefd9aa354",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_iter = 1\n",
    "MIN_VALIDATION_ACC = 0.65 #Stop training if validation accuracy reaches atleast MIN_VALIDATION_ACC\n",
    "metrics = {'validation_acc': []}\n",
    "train_acc,train_samples = 0,0\n",
    "\n",
    "#Training for one epoch\n",
    "monitor = ZeusMonitor(gpu_indices=[0])\n",
    "\n",
    "try:\n",
    "    monitor.begin_window(\"model_train\")\n",
    "# if the last measurement window is still running\n",
    "except ValueError:\n",
    "    _ = monitor.end_window(\"model_train\")\n",
    "    monitor.begin_window(\"model_train\")\n",
    "\n",
    "for epoch in range(n_max_iter):\n",
    "\n",
    "    ##Train the model for one epoch\n",
    "\n",
    "    # Train on training data\n",
    "    train_one_epoch(train_loader)\n",
    "\n",
    "    # Evaluate on validation data\n",
    "    val_accuracy = eval_model(val_loader)\n",
    "    metrics['validation_acc'].append(val_accuracy)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{n_epochs} - Val_Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "    if(val_accuracy>=MIN_VALIDATION_ACC):\n",
    "        break\n",
    "\n",
    "measurement = monitor.end_window(\"model_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bac0c1b-4dc5-4f8a-82a5-904d3e0f61ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checkout enegy and time required for one epoch\n",
    "print(\"Measured time (s)  :\" , measurement.time)\n",
    "print(\"Measured energy (J):\" , measurement.total_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54171b65-ba9a-46cf-8dcd-86062cdf066c",
   "metadata": {},
   "source": [
    "### Reproducing the Figure\n",
    "\n",
    "Now, we run the above loop to `n_max_iter = 100` with varying batch\n",
    "sizes and GPU power limit and store the model performance and energy\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c310902-8dcd-4db9-bb46-f9174ec5337d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select all the batch size and GPU power limits to test\n",
    "batch_size_list = [2**bts for bts in range(3,11)] #Sizes ranging from 8 to 1024 increasing in powers of 2\n",
    "\n",
    "power_limit_list = [powlimit for powlimit in range(100,251,30)] #Power limit ranging from 100W to 350W with increments of 30W\n",
    "\n",
    "#We now sample `k` random pair of batch_sizes and power limits\n",
    "\n",
    "k = 5\n",
    "\n",
    "params = sorted(random.sample(list(zip(batch_size_list, power_limit_list)), k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3250809-d130-4f81-8aee-1d2d290c4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_iter = 100\n",
    "MIN_VALIDATION_ACC = 0.65 #Stop training if validation accuracy reaches atleast MIN_VALIDATION_ACC\n",
    "metrics = {'validation_acc': [],'time':[],'energy':[],'power_limit':[],'batch_size':[],'num_epochs'[]}\n",
    "train_acc,train_samples = 0,0\n",
    "\n",
    "#Training for one epoch\n",
    "monitor = ZeusMonitor(gpu_indices=[0])\n",
    "\n",
    "\n",
    "\n",
    "for (BATCH_SIZE, power_limit) in params:\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    pynvml.nvmlDeviceSetPowerManagementLimit(pynvmml.nvmlDeviceGetHandleByIndex(0),power_limit*1000) #Setting the power limit\n",
    "\n",
    "\n",
    "    try:\n",
    "        monitor.begin_window(\"model_train\")\n",
    "    # if the last measurement window is still running\n",
    "    except ValueError:\n",
    "        _ = monitor.end_window(\"model_train\")\n",
    "        monitor.begin_window(\"model_train\")\n",
    "    for epoch in range(n_max_iter):\n",
    "\n",
    "        ##Train the model for one epoch\n",
    "\n",
    "        # Train on training data\n",
    "        train_one_epoch(train_loader)\n",
    "\n",
    "        # Evaluate on validation data\n",
    "        val_accuracy = eval_model(val_loader)\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{n_epochs} - Val_Accuracy: {val_accuracy:.4f}')\n",
    "\n",
    "\n",
    "        if(val_accuracy>=MIN_VALIDATION_ACC):\n",
    "            break\n",
    "\n",
    "    measurement = monitor.end_window(\"model_train\")\n",
    "\n",
    "    #Saving the metrics\n",
    "    metrics['validation_acc'].append(val_accuracy)\n",
    "    metrics['time'].append(measurement.time)\n",
    "    metrics['energy'].append(measurement.total_energy)\n",
    "    metrics['power_limit'].append(power_limit)\n",
    "    metrics['batch_size'].append(BATCH_SIZE)\n",
    "    metrics['num_epocs'].append(epoch+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ef641-a512-4330-9ac4-787e938fd55f",
   "metadata": {},
   "source": [
    "# Plotting Energy Consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bc626d-a0ba-45fb-8053-2ad2a2900335",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy = measurement.total_energy\n",
    "time = measurement.time\n",
    "\n",
    "plt.scatter(energy, time)\n",
    "plt.xlabel('Training Time (s)')\n",
    "plt.ylabel('Energy Consumption (J)')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
