{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring energy comsumption of neural networks\n",
    "\n",
    "In the previous notebook, we trained a model to classify music. Now, we’ll explore what happens when we vary the training hyperparameters, but train each model to the same validation **accuracy target**. We will consider:\n",
    "\n",
    "-   how much *time* it takes to achieve that accuracy target (“time to accuracy”)\n",
    "-   how much *energy* it takes to achieve that accuracy target (“energy to accuracy”)\n",
    "-   and the *test accuracy* for the model, given that it is trained to the specified validation accuracy target"
   ],
   "id": "883138e6-7daf-4b64-88c3-1362579bbb4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib inline"
   ],
   "id": "4a436e90-87d3-4c93-85b5-5cbe9a7b984b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Input\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "import tensorflow.keras.backend as K"
   ],
   "id": "68223c0f-8411-46a1-a433-746f608ae1a9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "\n",
    "Here, we’ll load the processed data defined in the previous notebook"
   ],
   "id": "d3e1c563-4e21-49e0-a3b1-1410dc7025d3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr_scale = np.load('instrument_dataset/uiowa_std_scale_train_data.npy')\n",
    "ytr = np.load('instrument_dataset/uiowa_permuted_train_labels.npy')\n",
    "Xts_scale = np.load('instrument_dataset/uiowa_std_scale_test_data.npy')\n",
    "yts = np.load('instrument_dataset/uiowa_test_labels.npy')"
   ],
   "id": "9ee9fe35-8de2-4dc4-86a8-2fe631b715a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_UNITS = 256"
   ],
   "id": "4facf5f0-61c1-45f8-8d7f-4ec76237a783"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Energy consumption\n",
    "\n",
    "To do this, first we will need some way to measure the energy used to train the model. We will use [Zeus](https://ml.energy/zeus/overview/), a Python package developed by researchers at the University of Michigan, to measure the GPU energy consumption.\n",
    "\n",
    "**Note**: if you are running this experiment in a CPU-only runtime, you should skip this section on energy comsumption. Continue with the ” `TrainToAccuracy` callback” section."
   ],
   "id": "bfd5c471-f0bd-40d6-bd8b-c971dd0c3fe5"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the zeus-ml package, and tell it to monitor your GPU:"
   ],
   "id": "c1cdaa1a-4516-494d-8e2b-23af35ab53e1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zeus.monitor import ZeusMonitor\n",
    "\n",
    "monitor = ZeusMonitor()"
   ],
   "id": "ef802bcd-48d8-4084-ae20-093c6976c96f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you want to measure GPU energy usage, you will:\n",
    "\n",
    "-   start a “monitoring window”\n",
    "-   do your GPU-intensive computation (e.g. call `model.fit`)\n",
    "-   stop the “monitoring window”\n",
    "\n",
    "and then you can get the time and total energy used by the GPU in the monitoring window.\n",
    "\n",
    "Try it now - this will just continue fitting whatever `model` is currently in scope from previous cells:"
   ],
   "id": "dbad8f1d-148c-4375-a4ce-b8a668e7f2fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor.begin_window(\"test\")\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input((Xtr_scale.shape[1],)))\n",
    "model.add(Dense(NUM_UNITS, activation = 'sigmoid'))\n",
    "model.add(Dense(len(np.unique(ytr)), activation = 'softmax'))\n",
    "\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "\n",
    "model.compile(optimizer = opt, loss = loss_fn, metrics = ['accuracy'])\n",
    "\n",
    "model.fit(Xtr_scale, ytr, epochs=5)\n",
    "measurement = monitor.end_window(\"test\")\n",
    "print(\"Measured time (s)  :\" , measurement.time)\n",
    "print(\"Measured energy (J):\" , measurement.total_energy)"
   ],
   "id": "dee3e75c-cbb2-4b39-92a9-e32f2afcb8fd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `TrainToAccuracy` callback\n",
    "\n",
    "Next, we need a way to train a model until we achieve our desired validation accuracy. We will [write a callback function](https://www.tensorflow.org/guide/keras/writing_your_own_callbacks) following these specifications:\n",
    "\n",
    "-   It will be called `TrainToAccuracy` and will accept two arguments: a `threshold` and a `patience` value.\n",
    "-   If the model’s validation accuracy is higher than the `threshold` for `patience` epochs in a row, stop training.\n",
    "-   In the `on_epoch_end` function, which will be called at the end of every epoch during training, you should get the current validation accuracy using `currect_acc = logs.get(\"val_accuracy\")`. Then, set `self.model.stop_training = True` if the condition above is met.\n",
    "-   The default values of `threshold` and `patience` are given below, but other values may be passed as arguments at runtime.\n",
    "\n",
    "Then, when you call `model.fit()`, you will add the `TrainToAccuracy` callback as in\n",
    "\n",
    "    callbacks=[TrainToAccuracy(threshold=0.98, patience=5)]"
   ],
   "id": "ffa76dfe-b8f5-4b42-b151-a422141cd6e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - write a callback function\n",
    "class TrainToAccuracy(callbacks.Callback):\n",
    "\n",
    "    def __init__(self, threshold=0.9, patience=3):\n",
    "        self.threshold = threshold  # the desired accuracy threshold\n",
    "        self.patience = patience # how many epochs to wait once hitting the threshold\n",
    "        self.last_change_epoch = -1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_acc = logs.get(\"val_accuracy\")\n",
    "        if(current_acc>self.threshold):\n",
    "          if(epoch - self.last_change_epoch>=self.patience):\n",
    "            self.model.stop_training = True\n",
    "        else:\n",
    "          self.last_change_epoch = epoch\n",
    "        return"
   ],
   "id": "59cc630b-070c-4b32-935c-1cb23900bd66"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it! run the following cell to test your `TrainToAccuracy` callback. (This will just continue fitting whatever `model` is currently in scope.)"
   ],
   "id": "0bdeb2a9-0abf-48b4-a5b1-f6d6fca17fd1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(Xtr_scale, ytr, epochs=100, validation_split = 0.2, callbacks=[TrainToAccuracy(threshold=0.95, patience=5)])"
   ],
   "id": "39dd5cd6-917c-40a4-a3cf-57594ac0640a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your model shouldn’t *really* train for 100 epochs - it should stop training as soon as 95% validation accuracy is achieved for 5 epochs in a row! (Your “test” is not graded, you may change the `threshold` and `patience` values in this “test” call to `model.fit` in order to check your work.)\n",
    "\n",
    "Note that since we are now using the validation set performance to *decide* when to stop training the model, we are no longer “allowed” to pass the test set as `validation_data`. The test set must never be used to make decisions during the model training process - only for evaluation of the final model. Instead, we specify that 20% of the training data should be held out as a validation set, and that is the validation accuracy that is used to determine when to stop training."
   ],
   "id": "7c8135f0-d882-4834-8904-d2c07520abe6"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See how TTA/ETA varies with learning rate, batch size\n",
    "\n",
    "Now, you will repeat your model preparation and fitting code - with your new `TrainToAccuracy` callback - but in a loop. First, you will iterate over different learning rates.\n",
    "\n",
    "In each iteration of each loop, you will prepare a model (with the appropriate training hyperparameters) and train it until:\n",
    "\n",
    "-   either it has achieved **0.95 accuracy for 3 epoches in a row** on a 20% validation subset of the training data,\n",
    "-   or, it has trained for 500 epochs\n",
    "\n",
    "whichever comes FIRST."
   ],
   "id": "02a594d5-3d1b-4765-838e-77bafc1d689a"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each model, you will record:\n",
    "\n",
    "-   the training hyperparameters (learning rate, batch size)\n",
    "-   the number of epochs of training needed to achieve the target validation accuracy\n",
    "-   the accuracy on the *test* data (not the validation data!). After fitting the model, use `model.evaluate` and pass the scaled *test* data to get the test loss and test accuracy\n",
    "-   **GPU runtime**: the GPU energy and time to train the model to the desired validation accuracy, as computed by a `zeus-ml` measurement window that starts just before `model.fit` and ends just after `model.fit`.\n",
    "-   **CPU runtime**: the time to train the model to the desired validation accuracy, as computed by the difference in `time.time()` just before `model.fit` and just after `model.fit`."
   ],
   "id": "023e50cd-26cf-4b7c-a0ee-0fe510aa963e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO - iterate over learning rates and get TTA/ETA\n",
    "\n",
    "# default learning rate and batch size -\n",
    "batch_size = 128\n",
    "\n",
    "acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "metrics_vs_lr = []\n",
    "for lr in [0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
    "    # TODO - set up model, including appropriate optimizer hyperparameters\n",
    "    \n",
    "    model_test = Sequential()\n",
    "    model_test.add(Input((Xtr_scale.shape[1],)))\n",
    "    model_test.add(Dense(NUM_UNITS, activation = 'sigmoid'))\n",
    "    model_test.add(Dense(len(np.unique(ytr)), activation = 'softmax'))\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=lr)\n",
    "    model_test.compile(optimizer = opt, loss = loss_fn, metrics = ['accuracy'])\n",
    "\n",
    "    # start measurement\n",
    "    # if on GPU runtime\n",
    "    try:\n",
    "        monitor.begin_window(\"model_train\")\n",
    "    # if on GPU runtime, but last measurement window is still running\n",
    "    except ValueError:\n",
    "        _ = monitor.end_window(\"model_train\")\n",
    "        monitor.begin_window(\"model_train\")\n",
    "    # if on CPU runtime\n",
    "    except NameError:\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "    # TODO - fit model on (scaled) training data\n",
    "    # until specified validation accuracy is achieved (don't use test data!)\n",
    "    # but stop after 500 epochs even if validation accuracy is not achieved\n",
    "\n",
    "    hist_test = model_test.fit(Xtr_scale,ytr, batch_size = batch_size, epochs=500,\n",
    "                               validation_split = 0.2, callbacks=[TrainToAccuracy(threshold=0.95, patience=3)])\n",
    "\n",
    "    # end measurement\n",
    "    # if on GPU runtime\n",
    "    try:\n",
    "        measurement = monitor.end_window(\"model_train\")\n",
    "    # if on CPU runtime\n",
    "    except NameError:\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "    # TODO - evaluate model on (scaled) test data\n",
    "\n",
    "    test_acc = acc_metric(yts,model_test.predict(Xts_scale))\n",
    "\n",
    "    # save results in a dictionary\n",
    "    model_metrics = {\n",
    "       'batch_size': batch_size,\n",
    "       'learning_rate': lr,\n",
    "       'epochs': len(hist_test.history['loss']),\n",
    "       'test_accuracy': test_acc,\n",
    "       'total_energy': measurement.total_energy, # if on GPU runtime\n",
    "       'train_time': measurement.time\n",
    "    }\n",
    "\n",
    "    # TODO - append model_metrics dictionary to the metrics_vs_lr list\n",
    "    metrics_vs_lr.append(model_metrics)"
   ],
   "id": "c8fb128e-e58e-49d3-aee2-34e583655094"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will visualize the results.\n",
    "\n",
    "**GPU runtime instructions**: Create a figure with four subplots. In each subplot, create a bar plot with learning rate on the horizontal axis and (1) Time to accuracy, (2) Energy to accuracy, (3) Test accuracy, (4) Epochs, on the vertical axis on each subplot, respectively. Use an appropriate vertical range for each subplot. Label all axes."
   ],
   "id": "bce9b25a-eaf3-4684-a6ca-defd702f5295"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - visualize effect of varying learning rate, when training to a target accuracy\n",
    "plt.figure(figsize = (9,5))\n",
    "\n",
    "lr = [_['learning_rate'] for _ in metrics_vs_lr]\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "time_ = [_['train_time'] for _ in metrics_vs_lr]\n",
    "\n",
    "sns.barplot(x=lr, y=time_)\n",
    "plt.xlabel('LR');\n",
    "plt.ylabel('Train time')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "energy_ = [_['total_energy'] for _ in metrics_vs_lr]\n",
    "\n",
    "sns.barplot(x=lr, y=energy_)\n",
    "plt.xlabel('LR');\n",
    "plt.ylabel('Total Energy')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "test_acc_ = [_['test_accuracy'].cpu().numpy() for _ in metrics_vs_lr]\n",
    "\n",
    "sns.barplot(x=lr, y=test_acc_)\n",
    "plt.xlabel('LR');\n",
    "plt.ylabel('Test Accuracy')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "nepochs_ = [_['epochs'] for _ in metrics_vs_lr]\n",
    "\n",
    "sns.barplot(x=lr, y=nepochs_)\n",
    "plt.xlabel('LR');\n",
    "plt.ylabel('Num Epochs')\n",
    "plt.tight_layout()"
   ],
   "id": "ae4607d6-a15a-403c-8f73-4bccda1739d4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on the results**: Given that the model is trained to a target validation accuracy, what is the effect of the learning rate on the training process?\n",
    "\n",
    "Note: because of the stochastic nature of neural network training AND in the compute resource, these measurements can be very “noisy”. Look for overall trends, but don’t be concerned with small differences from one experiment to the next, or with occasional “outlier” results. Also note that if the number of epochs is 500, this is an indication that the target validation accuracy was *not* reached in 500 epochs!"
   ],
   "id": "2bf3b14b-4550-44d8-b85d-835be49378fc"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment** Effect of LR:\n",
    "\n",
    "-   Training time: If the LR is too high, the model does not converge, and the training process stops after hitting the maximum number of iterations. Hence the training time is the highest for these cases. When LR is very low, the convergence occurs very slowly. So the time taken is relatively higher than the case when the LR is ideal.\n",
    "-   Energy: Same trend as time. More the time, the higher the energy .\n",
    "-   Test accuracy: If the model converges, the test accuracy reaches the maximum (for LR in {.0001,.001,.01}. For very high LRs, the model does not converge hence the test accuracy is lower.\n",
    "-   Num epochs: Same trend as time since the batch size is the same.\n",
    "\n",
    "Now, you will repeat, with a loop over different batch sizes -"
   ],
   "id": "67d9b952-fd65-4e7d-a10d-c6b1ae8988c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - iterate over batch size and get TTA/ETA\n",
    "\n",
    "# default learning rate and batch size -\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "\n",
    "metrics_vs_bs = []\n",
    "for batch_size in [64, 128]:#, 256, 512, 1024, 2048]:\n",
    "\n",
    "    # TODO - set up model, including appropriate optimizer hyperparameters\n",
    "    \n",
    "    model_test = Sequential()\n",
    "    model_test.add(Input((Xtr_scale.shape[1],)))\n",
    "    model_test.add(Dense(NUM_UNITS, activation = 'sigmoid'))\n",
    "    model_test.add(Dense(len(np.unique(ytr)), activation = 'softmax'))\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=lr)\n",
    "    model_test.compile(optimizer = opt, loss = loss_fn, metrics = ['accuracy'])\n",
    "\n",
    "    # start measurement\n",
    "    # if on GPU runtime\n",
    "    try:\n",
    "        monitor.begin_window(\"model_train\")\n",
    "    # if on GPU runtime, but last measurement window is still running\n",
    "    except ValueError:\n",
    "        _ = monitor.end_window(\"model_train\")\n",
    "        monitor.begin_window(\"model_train\")\n",
    "    # if on CPU runtime\n",
    "    except NameError:\n",
    "        start_time = time.time()\n",
    "\n",
    "\n",
    "    # TODO - fit model on (scaled) training data\n",
    "    # until specified validation accuracy is achieved (don't use test data!)\n",
    "    # but stop after 500 epochs even if validation accuracy is not achieved\n",
    "\n",
    "    hist_test = model_test.fit(Xtr_scale,ytr, batch_size = batch_size, epochs=500,\n",
    "                               validation_split = 0.2, callbacks=[TrainToAccuracy(threshold=0.95, patience=3)])\n",
    "\n",
    "    # end measurement\n",
    "    # if on GPU runtime\n",
    "    try:\n",
    "        measurement = monitor.end_window(\"model_train\")\n",
    "    # if on CPU runtime\n",
    "    except NameError:\n",
    "        total_time = time.time() - start_time\n",
    "\n",
    "    # TODO - evaluate model on (scaled) test data\n",
    "\n",
    "    test_acc = acc_metric(yts,model_test.predict(Xts_scale))\n",
    "\n",
    "    # save results in a dictionary\n",
    "    model_metrics = {\n",
    "       'batch_size': batch_size,\n",
    "       'learning_rate': lr,\n",
    "       'epochs': len(hist_test.history['loss']),\n",
    "       'test_accuracy': test_acc,\n",
    "       'total_energy': measurement.total_energy, # if on GPU runtime\n",
    "       'train_time': measurement.time\n",
    "    }\n",
    "\n",
    "    # TODO - append model_metrics dictionary to the metrics_vs_lr list\n",
    "    metrics_vs_bs.append(model_metrics)"
   ],
   "id": "6e3e5f82-fade-4c40-b7ea-c43de9a1e85f"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will visualize the results.\n",
    "\n",
    "**GPU runtime instructions**: Create a figure with four subplots. In each subplot, create a bar plot with batch size on the horizontal axis and (1) Time to accuracy, (2) Energy to accuracy, (3) Test accuracy, (4) Epochs, on the vertical axis on each subplot, respectively. Use an appropriate vertical range for each subplot. Label all axes."
   ],
   "id": "0173d943-02c6-48e4-a533-a87c392ee6a0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - visualize effect of varying batch size, when training to a target accuracy\n",
    "plt.figure(figsize = (9,5))\n",
    "batch_ls = [_['batch_size'] for _ in metrics_vs_bs]\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "time_ = [_['train_time'] for _ in metrics_vs_bs]\n",
    "\n",
    "sns.barplot(x=batch_ls, y=time_)\n",
    "plt.xlabel('Batch Size');\n",
    "plt.ylabel('Train time')\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "energy_ = [_['total_energy'] for _ in metrics_vs_bs]\n",
    "\n",
    "sns.barplot(x=batch_ls, y=energy_)\n",
    "plt.xlabel('Batch Size');\n",
    "plt.ylabel('Total Energy')\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "test_acc_ = [_['test_accuracy'].cpu().numpy() for _ in metrics_vs_bs]\n",
    "\n",
    "sns.barplot(x=batch_ls, y=test_acc_)\n",
    "plt.xlabel('Batch Size');\n",
    "plt.ylabel('Test Accuracy')\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "nepochs_ = [_['epochs'] for _ in metrics_vs_bs]\n",
    "\n",
    "sns.barplot(x=batch_ls, y=nepochs_)\n",
    "plt.xlabel('Batch Size');\n",
    "plt.ylabel('Num Epochs')\n",
    "plt.tight_layout()"
   ],
   "id": "b74bbc62-8644-48c8-951b-18b3564da0fd"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment on the results**: Given that the model is trained to a target validation accuracy, what is the effect of the batch size on the training process?\n",
    "\n",
    "Note: because of the stochastic nature of neural network training AND in the compute resource, these measurements can be very “noisy”. Look for overall trends, but don’t be concerned with small differences from one experiment to the next, or with occasional “outlier” results. Also note that if the number of epochs is 500, this is an indication that the target validation accuracy was *not* reached in 500 epochs!"
   ],
   "id": "bb643768-a73e-4b8a-8b87-1feffa8027e9"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
