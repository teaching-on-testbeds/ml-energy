{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a single user notebook server on Chameleon\n",
    "\n",
    "This notebook describes how to run a single user Jupyter notebook server on Chameleon. This allows you to run experiments requiring bare metal access, storage, memory, GPU and compute resources on Chameleon using a Jupyter notebook interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provision the resource\n",
    "\n",
    "### Check resource availability\n",
    "\n",
    "This notebook will try to reserve a RTX6000 GPU backed Ubuntu-22.04 on CHI@UC - pending availability. Before you begin, you should check the host calendar at https://chi.uc.chameleoncloud.org/project/leases/calendar/host/ to see what node types are available.\n",
    "\n",
    "### Chameleon configuration\n",
    "\n",
    "You can change your Chameleon project name (if not using the one that is automatically configured in the JupyterHub environment) and the site on which to reserve resources (depending on availability) in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chi, os, time\n",
    "from chi import lease\n",
    "from chi import server\n",
    "\n",
    "PROJECT_NAME = os.getenv('OS_PROJECT_NAME') # change this if you need to\n",
    "chi.use_site(\"CHI@UC\")\n",
    "chi.set(\"project_name\", PROJECT_NAME)\n",
    "username = os.getenv('USER') # all exp resources will have this prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name=\"CC-Ubuntu22.04-CUDA\"\n",
    "NODE_TYPE = \"gpu_rtx_6000\"\n",
    "\n",
    "chi.set(\"image\", image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reservation\n",
    "\n",
    "The following cell will create a reservation that begins now, and ends in 8 hours. You can modify the start and end date as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "lease.add_node_reservation(res, node_type=NODE_TYPE, count=1)\n",
    "lease.add_fip_reservation(res, count=1)\n",
    "\n",
    "start_date, end_date = lease.lease_duration(days=0, hours=8)\n",
    "# if you won't start right now - comment the line above, uncomment two lines below\n",
    "# start_date = '2024-04-02 15:24' # manually define to desired start time \n",
    "# end_date = '2024-04-03 01:00' # manually define to desired start time \n",
    "\n",
    "\n",
    "l = lease.create_lease(f\"{username}-{NODE_TYPE}\", res, start_date=start_date, end_date=end_date)\n",
    "l = lease.wait_for_active(l[\"id\"]) #Comment this line if the lease starts in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# continue here, whether using a lease created just now or one created earlier\n",
    "l = lease.get_lease(f\"{username}-{NODE_TYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provisioning resources\n",
    "\n",
    "This cell provisions resources. It will take approximately 10 minutes. You can check on its status in the Chameleon web-based UI: https://chi.uc.chameleoncloud.org/project/instances/, then come back here when it is in the READY state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservation_id = lease.get_node_reservation(l[\"id\"])\n",
    "server.create_server(\n",
    "    f\"{username}-{NODE_TYPE}\", \n",
    "    reservation_id=reservation_id,\n",
    "    image_name=image_name\n",
    ")\n",
    "server_id = server.get_server_id(f\"{username}-{NODE_TYPE}\")\n",
    "server.wait_for_active(server_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate an IP address with this server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserved_fip = server.associate_floating_ip(server_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And wait for it to come up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.wait_for_tcp(reserved_fip, port=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Stuff\n",
    "\n",
    "The following cells will install some basic packages for your Chameleon server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chi import ssh\n",
    "\n",
    "node = ssh.Remote(reserved_fip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run('sudo apt update')\n",
    "node.run('sudo apt -y install python3-pip python3-dev')\n",
    "node.run('sudo pip3 install --upgrade pip')\n",
    "node.run('sudo apt -y install libcudnn8=8.9.6.50-1+cuda12.2') #Installing libcudnn8=8.9.6.50-1+cuda12.2 because it is the most recent one supported by TF-2.16.1\n",
    "node.run('sudo apt -y install pandoc')\n",
    "node.run('sudo apt -y install ffmpeg=7:4.4.2-0ubuntu0.22.04.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add cuda to the environment path to ensure that the machine can identify the drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run(\"echo 'PATH=\\\"/usr/local/cuda-12.3/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin\\\"' | sudo tee /etc/environment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now reboot the server for all the installations to patch correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    node.run('sudo reboot') # reboot and wait for it to come up\n",
    "except:\n",
    "    pass\n",
    "server.wait_for_tcp(reserved_fip, port=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = ssh.Remote(reserved_fip) # note: need a new SSH session to get new PATH\n",
    "node.run('nvidia-smi')\n",
    "node.run('nvcc --version')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run('python3 -m pip install --user tensorflow[and-cuda]==2.16.1')\n",
    "node.run('python3 -m pip install --user numpy==1.26.4')\n",
    "node.run('python3 -m pip install --user matplotlib==3.8.4')\n",
    "node.run('python3 -m pip install --user seaborn==0.13.2')\n",
    "node.run('python3 -m pip install --user librosa==0.10.1')\n",
    "node.run('python3 -m pip install --user zeus-ml==0.8.2')\n",
    "node.run('python3 -m pip install --user torch==2.2.2 torchvision==0.17.2 torchaudio==-2.2.2')\n",
    "node.run('python3 -m pip install --user pydot==2.0.0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your installation - make sure Tensorflow can see the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run('python3 -c \\'import tensorflow as tf; print(tf.config.list_physical_devices(\"GPU\"))\\'')\n",
    "# should say: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make sure torch can see the GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run('python3 -c \\'import torch; print(torch.cuda.get_device_name(0))\\'')\n",
    "# should say: Quadro RTX 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Jupyter on server\n",
    "\n",
    "Install Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run('python3 -m pip install --user  jupyter-core jupyter-client jupyter -U --force-reinstall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve the materials\n",
    "\n",
    "Finally, get a copy of the notebooks that you will run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run('git clone https://github.com/teaching-on-testbeds/ml-energy.git')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a JupyterHub server\n",
    "\n",
    "Run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('ssh -L 127.0.0.1:8888:127.0.0.1:8888 cc@' + reserved_fip) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then paste its output into a local terminal on your own device, to set up a tunnel to the Jupyter server. Make sure that 8888 port on your local machine is free before running this command. Upon successful login and tunneling, you should see this output.\n",
    "\n",
    "    Welcome to Ubuntu 22.04.4 LTS (GNU/Linux 5.15.0-101-generic x86_64)\n",
    "    Last login: xxxxxxxxxxxxxx\n",
    "\n",
    "If your Chameleon key is not in the default location, you should also specify the path to your key as an argument, using -i. For instance,\n",
    "\n",
    "``` python\n",
    "ssh -L 127.0.0.1:8888:127.0.0.1:8888 -i <SSH_KEYPATH> cc@<RESERVED_FIP>\n",
    "```\n",
    "\n",
    "Leave this SSH session open.\n",
    "\n",
    "Then, run the following cell, which will start a command that does not terminate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run(\"/home/cc/.local/bin/jupyter notebook --port=8888 --notebook-dir='/home/cc/ml-energy/notebooks/'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output of the cell above, look for a URL in this format:\n",
    "\n",
    "http://localhost:8888/?token=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX Copy this URL and open it in a browser. Then, you can run the sequence of notebooks that you’ll see there, in order.\n",
    "\n",
    "If you need to stop and re-start your Jupyter server,\n",
    "\n",
    "-   Use Kernel \\> Interrupt Kernel twice to stop the cell above\n",
    "-   Then run the following cell to kill whatever may be left running in the background.\n",
    "\n",
    "Note: If the message `The port 8888 is already in use, trying another port.` appears in the output of the above cell, it implies that the local port 8888 is busy i.e. being used by someother process. Note the port the notebook was launched at. `localhost:XXXX`, XXXX is the port of interest.\n",
    "\n",
    "Quit the ssh running on the local machine from the cell above and replace it with\n",
    "\n",
    "``` python\n",
    "ssh -L 127.0.0.1:8888:127.0.0.1:XXXX -i <SSH_KEYPATH> cc@<RESERVED_FIP>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.run(\"sudo killall jupyter-notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Resources\n",
    "\n",
    "If you finish with your experimentation before your lease expires,release your resources and tear down your environment by running the following (commented out to prevent accidental deletions).\n",
    "\n",
    "This section is designed to work as a “standalone” portion - you can come back to this notebook, ignore the top part, and just run this section to delete your reasources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup environment - if you made any changes in the top part, make the same changes here\n",
    "import chi, os\n",
    "from chi import lease, server\n",
    "\n",
    "PROJECT_NAME = PROJECT_NAME\n",
    "chi.use_site(\"CHI@UC\")\n",
    "chi.set(\"project_name\", PROJECT_NAME)\n",
    "username = os.getenv('USER')\n",
    "\n",
    "lease = chi.lease.get_lease(f\"{username}-{NODE_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELETE = False #Default value is False to prevent any accidental deletes. Change it to True for deleting the resources\n",
    "\n",
    "if DELETE:\n",
    "    # delete server\n",
    "    server_id = chi.server.get_server_id(f\"{username}-{NODE_TYPE}\")\n",
    "    chi.server.delete_server(server_id)\n",
    "\n",
    "    # release floating IP\n",
    "    reserved_fip =  chi.lease.get_reserved_floating_ips(lease[\"id\"])[0]\n",
    "    ip_info = chi.network.get_floating_ip(reserved_fip)\n",
    "    chi.neutron().delete_floatingip(ip_info[\"id\"])\n",
    "\n",
    "    # delete lease\n",
    "    chi.lease.delete_lease(lease[\"id\"])"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 }
}
